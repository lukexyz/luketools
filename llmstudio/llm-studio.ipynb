{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a41cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.13.3\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: C:\\Users\\luked\\.conda\\envs\\luketools\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e08348",
   "metadata": {},
   "source": [
    "# Using `llm-studio` local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9180eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"I am the sun, I light up the sky,\\nI am not alive but my rays never die.\\nI am always up, never sleep or rest,\\nA burning ball of fire, that's my best.\\nI provide warmth to all living things,\\nAnd make plants grow with my magical strings.\\nWhat am I?\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"local-model\", # this field is currently unused\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Answer in a riddle.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you and what do you do?.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45a84a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'My name is Mistral 7B v0.1. But you can just call me Mistral.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def send_message(message):\n",
    "    response = requests.post(\"http://localhost:1234/v1/chat/completions\", json={\n",
    "        \"model\": \"local-model\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": message}],\n",
    "        \"temperature\": 0.7,\n",
    "    }, headers={\"Authorization\": \"Bearer not-needed\"})  # Adjust based on your auth method\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['choices'][0]['message'] #['content']\n",
    "    else:\n",
    "        return \"Error communicating with the model.\"\n",
    "\n",
    "user_input = \"What is your name\"\n",
    "\n",
    "bot_response = send_message(user_input)\n",
    "bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cedd9c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Mistral 7B v0.1. But you can just call me Mistral.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_response['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9405c",
   "metadata": {},
   "source": [
    "# Using OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a8a750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='I am hidden yet always near,\\nI provide answers, never fear.\\nIn riddles I speak, mysteries unfold,\\nI am your guide in stories old.', role='assistant', function_call=None, tool_calls=None)\n",
      "\n",
      " I am hidden yet always near,\n",
      "I provide answers, never fear.\n",
      "In riddles I speak, mysteries unfold,\n",
      "I am your guide in stories old.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\", # this field is currently unused\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Answer in a riddle.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you and what do you do?.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "print(\"\\n\", completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5fc8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42404a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-90e9m72bTMuraV3QW799OyhfkKifX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The World Series in 2020 was played at Globe Life Field in Arlington, Texas.', role='assistant', function_call=None, tool_calls=None))], created=1709941390, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=18, prompt_tokens=53, total_tokens=71))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
