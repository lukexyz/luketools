{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a41cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.13.3\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: d:\\programdata\\anaconda3.9\\lib\\site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: llm\n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9180eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"I am the sun, I light up the sky,\\nI am not alive but my rays never die.\\nI am always up, never sleep or rest,\\nA burning ball of fire, that's my best.\\nI provide warmth to all living things,\\nAnd make plants grow with my magical strings.\\nWhat am I?\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"local-model\", # this field is currently unused\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Answer in a riddle.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you and what do you do?.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45a84a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'My name is Mistral 7B v0.1. But you can just call me Mistral.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def send_message(message):\n",
    "    response = requests.post(\"http://localhost:1234/v1/chat/completions\", json={\n",
    "        \"model\": \"local-model\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": message}],\n",
    "        \"temperature\": 0.7,\n",
    "    }, headers={\"Authorization\": \"Bearer not-needed\"})  # Adjust based on your auth method\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['choices'][0]['message'] #['content']\n",
    "    else:\n",
    "        return \"Error communicating with the model.\"\n",
    "\n",
    "user_input = \"What is your name\"\n",
    "\n",
    "bot_response = send_message(user_input)\n",
    "bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cedd9c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Mistral 7B v0.1. But you can just call me Mistral.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_response['content']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
